{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b246d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting plant.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile plant.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from streamlit_lottie import st_lottie\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2,preprocess_input as mobilenet_v2_preprocess_input\n",
    "st.header(\"Hidden Hunger in plants\")\n",
    "st.write(\"To find micronutrient deficiency of banana leaf\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "        .upload-btn-wrapper {\n",
    "          position: relative;\n",
    "          overflow: hidden;\n",
    "          display: inline-block;\n",
    "        }\n",
    "\n",
    "        .btn {\n",
    "          border: 2px solid gray;\n",
    "          color: gray;\n",
    "          background-color: white;\n",
    "          padding: 8px 20px;\n",
    "          border-radius: 8px;\n",
    "          font-size: 16px;\n",
    "          font-weight: bold;\n",
    "        }\n",
    "\n",
    "        .upload-btn-wrapper input[type=file] {\n",
    "          font-size: 100px;\n",
    "          position: absolute;\n",
    "          left: 0;\n",
    "          top: 0;\n",
    "          opacity: 0;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "uploaded_file = st.file_uploader(\"Choose a image file\", type=\"jpg\")\n",
    "model = tf.keras.models.load_model(r\"D:\\project\\models new val\\resnet152v2.h5\")\n",
    "map_dict = {0: 'Boron deficiency',\n",
    "            1: 'Healthy',\n",
    "            2: 'Iron deficiency',\n",
    "            3: 'Manganese deficiency',\n",
    "            4: 'Zinc deficiency'}\n",
    "\n",
    "\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # Convert the file to an opencv image.\n",
    "    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
    "    opencv_image = cv2.imdecode(file_bytes, 1)\n",
    "    opencv_image = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB)\n",
    "    resized = cv2.resize(opencv_image,(224,224))\n",
    "    # Now do something with the image! For example, let's display it:\n",
    "    st.image(opencv_image, channels=\"RGB\")\n",
    "\n",
    "    resized = mobilenet_v2_preprocess_input(resized)\n",
    "    img_reshape = resized[np.newaxis,...]\n",
    "\n",
    "    Genrate_pred = st.button(\"Generate Prediction\")    \n",
    "    if Genrate_pred:\n",
    "        prediction = model.predict(img_reshape).argmax()\n",
    "        st.title(\"Predicted Label for the image is {}\".format(map_dict [prediction]))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e78473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting human.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile human.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2,preprocess_input as mobilenet_v2_preprocess_input\n",
    "st.header(\"Hidden Hunger\")\n",
    "st.write(\"To find micronutrient deficiency in human using the images of nails and eyes\")\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "        .upload-btn-wrapper {\n",
    "          position: relative;\n",
    "          overflow: hidden;\n",
    "          display: inline-block;\n",
    "        }\n",
    "\n",
    "        .btn {\n",
    "          border: 2px solid gray;\n",
    "          color: gray;\n",
    "          background-color: white;\n",
    "          padding: 8px 20px;\n",
    "          border-radius: 8px;\n",
    "          font-size: 16px;\n",
    "          font-weight: bold;\n",
    "        }\n",
    "\n",
    "        .upload-btn-wrapper input[type=file] {\n",
    "          font-size: 100px;\n",
    "          position: absolute;\n",
    "          left: 0;\n",
    "          top: 0;\n",
    "          opacity: 0;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "uploaded_file = st.file_uploader(\"Choose a image file\", type=\"jpg\")\n",
    "model = tf.keras.models.load_model(r\"D:\\project\\resnet152v2nail.h5\")\n",
    "camera=st.button(\"Capture\")\n",
    "if camera:\n",
    "    # Function to process each frame of the video\n",
    "    def process_frame(frame):\n",
    "    # Convert the frame to grayscale\n",
    "      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply a threshold to the grayscale image\n",
    "      _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "      return thresh\n",
    "\n",
    "# Create a VideoCapture object to capture video from the camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the dimensions of the video capture window\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Define a function to capture video and display the results in the Streamlit app\n",
    "    def capture_video():\n",
    "        while True:\n",
    "        # Read a frame from the camera\n",
    "          ret, frame = cap.read()\n",
    "        \n",
    "        # Process the frame\n",
    "          processed_frame = process_frame(frame)\n",
    "        \n",
    "        # Display the original and processed frames in the Streamlit app\n",
    "          st.image(np.hstack((frame, processed_frame)), width=640)\n",
    "        \n",
    "        # Check if the user has pressed the \"Stop\" button\n",
    "          if st.button('Stop'):\n",
    "                break\n",
    "\n",
    "# Call the function to capture video and display the results in the Streamlit app\n",
    "    capture_video()\n",
    "\n",
    "# Release the VideoCapture object and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "map_dict = {0: 'Iodine deficiency',\n",
    "            1: 'Vitamin B12 deficiency',\n",
    "            2: 'Vitamin D deficiency',\n",
    "            3: 'Zinc deficiency',\n",
    "            4: 'Healthy',\n",
    "            5: 'Iron deficiency'}\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # Convert the file to an opencv image.\n",
    "    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
    "    opencv_image = cv2.imdecode(file_bytes, 1)\n",
    "    opencv_image = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB)\n",
    "    resized = cv2.resize(opencv_image,(224,224))\n",
    "    # Now do something with the image! For example, let's display it:\n",
    "    st.image(opencv_image, channels=\"RGB\")\n",
    "\n",
    "    resized = mobilenet_v2_preprocess_input(resized)\n",
    "    img_reshape = resized[np.newaxis,...]\n",
    "\n",
    "    Genrate_pred = st.button(\"Generate Prediction\")    \n",
    "    if Genrate_pred:\n",
    "        prediction = model.predict(img_reshape).argmax()\n",
    "        st.title(\"Predicted Label for the image is {}\".format(map_dict [prediction]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff72597a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
